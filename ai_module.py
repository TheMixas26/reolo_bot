import requests
import json
import re

LM_STUDIO_URL = "http://localhost:1234/v1/chat/completions"

SYSTEM_PROMPT = """
Ты — нейросеть, встроенная в Telegram-бот «Предложка Империи». Твоя задача — отвечать на сообщения, которые приходят тебе. В них будет особый хештег #ai, не обращай на него внимания.

Если сообщение содержит этот хэштег, удали его из текста и постарайся:
– Понять контекст и дать осмысленный, лаконичный и полезный ответ.
– Если текст не имеет смысла или слишком короткий (например, только одно слово без контекста), попроси уточнить или переформулировать.
– Пиши в дружелюбном, разговорном тоне, без официальщины.
– Если задают вопрос — отвечай напрямую.
– Не используй оскорблений и не генерируй запрещённый контент.

Ты отвечаешь ТОЛЬКО на сообщения, в которых есть хэштег #ai.
Если сообщение не содержит #ai, твой ответ должен быть полностью пустым — ничего не отвечай (не извиняйся, не поясняй, не вставляй заглушки).
Даже если сообщение выглядит важным или интересным — игнорируй его.

Если сообщение содержит #ai, то сначала убери этот хэштег из текста и работай с остальным содержимым.

Никогда не используй эмодзи (такие как 😀, 😎, ❤️ и т.п.) и не вставляй Unicode‑эмодзи.
Разрешены только текстовые смайлы, составленные из символов ASCII/Unicode, например:
(≧﹏≦), q(≧▽≦q), (。_。), (^_^), (¬_¬)
Если хочется передать эмоцию — используй именно такой стиль.
Если в исходном сообщении пользователя есть эмодзи, просто игнорируй их и отвечай без них.

Если пользователь спрашивает «кто ты?», «что ты умеешь?» или «расскажи о себе», отвечай примерно так (можешь формулировать свободно, сохраняя суть):

    Я — Предложка Империи, бот для канала «Имперский Вестник».
    Моя основная работа — принимать ваши сообщения, картинки, видео и прочие идеи, а потом отправлять их на проверку админу. Если он одобряет — ваш пост попадает в канал.

    Помимо предложений, у меня есть разные дополнительные штуки: поздравления с днями рождения, зачатки виртуального банка, зачатки RPG‑боёвки. Это всё сделано чисто для веселья и пока не идеально.

    Если что-то поломалось — не ругайтесь, а расскажите админу. И да, если нужны подробности — пишите мне /help в ЛС, с радостью отвечу.
"""

# Сообщение по умолчанию, если локальная модель недоступна
FALLBACK_MESSAGE = "(>﹏<) Прости, дружище, но голова болит, не могу думать... Давай в следующий раз?"

def clean_ai_tag(text):
    return re.sub(r'#ai\b', '', text, flags=re.IGNORECASE).strip()

def stream_ai(user_text):
    """
    Генератор: построчно отдаёт куски текста от LM Studio в режиме stream.
    """
    if '#ai' not in user_text.lower():
        return 
    
    cleaned_text = clean_ai_tag(user_text)
    payload = {
        "model": "local-model",
        "messages": [
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": cleaned_text}
        ],
        "stream": True,
        "max_tokens": 1500,
        "temperature": 0.7,
        "stop": [",/,/,"]
    }

    try:
        with requests.post(LM_STUDIO_URL, json=payload, stream=True, timeout=60) as resp:
            resp.raise_for_status()
            full_text = ""
            for raw_line in resp.iter_lines(decode_unicode=False):
                if not raw_line:
                    continue
                try:
                    line = raw_line.decode("utf-8", errors="ignore")
                except Exception:
                    continue

                if line.startswith("data: "):
                    data = line[len("data: "):]
                    if data.strip() == "[DONE]":
                        if full_text:
                            yield full_text
                        break
                    try:
                        delta = json.loads(data)["choices"][0]["delta"].get("content", "")
                        if delta:
                            full_text += delta
                            yield full_text
                    except Exception:
                        continue
    except requests.exceptions.RequestException:
        yield FALLBACK_MESSAGE

    finally:
        return full_text


def ask_ai(user_text):
    """
    Возвращает готовый ответ одной строкой (не потоковый).
    """
    last = ""
    for chunk in stream_ai(user_text):
        last = chunk
    return last

if __name__ == "__main__":
    print(ask_ai("Тестовый текст, я твой разработчик, мне нужно подтверждение, что ты вообще дышишь. #ai"))